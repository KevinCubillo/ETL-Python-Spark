{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2498e772",
   "metadata": {},
   "source": [
    "La siguiente celda se encargara de importar todos los paquetes necesarios para el desarrollo del proyecto. Además, se importa el archivo de configuración de la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import ltrim,rtrim,trim,col\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.jars\", \"../lib/postgresql-42.5.1.jar\") \\\n",
    "\t.master(\"local\").appName(\"PySpark_Postgres_test\").getOrCreate()\n",
    "\n",
    "conn = psycopg2.connect(\"host=localhost dbname=etl user=postgres password=Legolas00\")\n",
    "engine = create_engine('postgresql://postgres:Legolas00@localhost:5432/etl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3875913",
   "metadata": {},
   "source": [
    "En la siguiente celda se encarga de utilizar spark para cargar en dos diferentes dataframes los datos del INEC y el OIJ para despues limpiarlos y unirlos en un solo dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5739b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DATAFRAME FROM CSV FILE\n",
    "oij_df = spark.read.csv( path=\"../data/OIJ.csv\", sep=\";\", header=True,quote='\"',inferSchema=True,)\n",
    "inec_df = spark.read.csv( path=\"../data/INEC.csv\", sep=\";\", header=True,quote='\"',inferSchema=True,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e379181",
   "metadata": {},
   "source": [
    "En la siguiente celda se encarga de realizar la limpieza de los datos del INEC y el OIJ. Primero se creo una función para remover todos los espacios en blanco al inicio y al final de cada sub celda del data frame utilizando la funcion trim para ello. Ademas se creo una funcio la cual se encarga de pasar todos los caracteres a letras minusculas para poder realizar la busqueda de los datos en el data frame. Los parametros de las funciones son un dataframe y el retorno es el mismo dataframe pero con los datos limpios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dfe503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(df):\n",
    "    for col in df.columns:\n",
    "        if  col == 'Provincia' or col == 'Canton' or col == 'Distrito' or col == 'Provincia, cantón y distrito':\n",
    "            df = df.withColumn(col, trim(col))\n",
    "    return df\n",
    "\n",
    "#Function to parser the string to lowercase\n",
    "def to_lower_case(df):\n",
    "    for col in df.columns:\n",
    "        if  col == 'Provincia' or col == 'Canton' or col == 'Distrito' or col == 'Provincia, cantón y distrito':\n",
    "            df = df.withColumn(col, lower(col))\n",
    "    return df\n",
    "\n",
    "\n",
    "oij_df = remove_spaces(oij_df)\n",
    "inec_df = remove_spaces(inec_df)\n",
    "\n",
    "oij_df = to_lower_case(oij_df)\n",
    "inec_df = to_lower_case(inec_df)\n",
    "\n",
    "oij_df.show(5)\n",
    "inec_df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca16b2ba",
   "metadata": {},
   "source": [
    "En la siguiente celda se encarga de reemplazar todos los caracteres especiales del español por caracteres ascii para poder realizar la busqueda de los datos en el data frame. Y que su taza de concidencia sea mayor.Para este trabajo se utilizo la funcionalidad regex_replace de spark. Y asi cada vez que se encuentre un caracter especial se reemplazara por un caracter ascii. El parametro de la funcion es un dataframe y el retorno es el mismo dataframe pero con los datos limpios es decir sin caracteres especiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to replace the accents in column Provincia, cantón y distrito in inec_df\n",
    "def replace_accents(df):\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'á', 'a'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'é', 'e'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'í', 'i'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'ó', 'o'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'ú', 'u'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'ñ', 'n'))\n",
    "    return df\n",
    "\n",
    "inec_df = replace_accents(inec_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d55c12f7",
   "metadata": {},
   "source": [
    "En la siguiente celda se encarga de dividir la columna del dataframe del inec en tres columnas diferentes, una para la provincia, otra para el canton y otra para el distrito. Para esto se creo una funcion que basado en la cantidad espacios que se encuentren en la columna se dividira en tres columnas diferentes. Esto para que la comparacion de los datos sea mas exacta. El parametro de la funcion es un dataframe y el retorno es el mismo dataframe pero con las columnas divididas en tres columnas diferentes para la provincia, canton y distrito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ffe418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_columns(df):\n",
    "    columns = [\"Provincia\", \"Canton\", \"Distrito\",\"poblacionMayor15\", \"tasaParticipacion\", \"tasaOcupacion\", \"tasaDesempleo\", \"poblacionInactiva\", \"relacionDependencia\"]\n",
    "    new_df = spark.createDataFrame(data =[(\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\")], schema = columns)\n",
    "    Provincia =''\n",
    "    Canton = ''\n",
    "    Distrito = ''\n",
    "    counter = 0\n",
    "    counter2 = 0\n",
    "    for row in df.collect():\n",
    "        if row['Provincia, cantón y distrito'] == None:\n",
    "            counter += 1\n",
    "            counter2 += 1\n",
    "            if counter == 4: \n",
    "                counter = 2  \n",
    "\n",
    "            if counter2 == 2:\n",
    "                counter = 1\n",
    "            continue\n",
    "        if counter == 1:\n",
    "            Provincia = row[0]\n",
    "        if counter == 2:\n",
    "            Canton = row[0]\n",
    "        if counter == 3:\n",
    "            Distrito = row[0]\n",
    "            poblacionMayor15 = row[1]\n",
    "            tasaParticipacion = row[2]\n",
    "            tasaOcupacion = row[3]\n",
    "            tasaDesempleo = row[4]\n",
    "            poblacionInactiva = row[5]\n",
    "            relacionDependencia = row[6]\n",
    "            NewRow = (Provincia, Canton, Distrito, poblacionMayor15, tasaParticipacion, tasaOcupacion, tasaDesempleo, poblacionInactiva, relacionDependencia)\n",
    "            new_df = new_df.union(spark.createDataFrame(data =[NewRow], schema = columns))\n",
    "        counter2 = 0\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "new_df = generate_new_columns(inec_df)\n",
    "new_df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0085bc82",
   "metadata": {},
   "source": [
    "En la siguiente celda la funcion se encarga de encontrar los datos que no hacen match entre el dataframe del inec y el dataframe del oij. Para esto se utilizo la funcion de subtract. El parametro de la funcion son dos dataframes y el retorno es una lista con los datos que no hacen match entre los dos dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d76ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_matches(df1,df2):\n",
    "    nonMatches = []\n",
    "    Province = ''\n",
    "    Canton = ''\n",
    "    District = ''\n",
    "    df1Temp = df1.select(\"Provincia\", \"Canton\", \"Distrito\")\n",
    "    df2Temp = df2.select(\"Provincia\", \"Canton\", \"Distrito\")\n",
    "    df1Temp = df1Temp.subtract(df2Temp)\n",
    "    for row in df1Temp.collect():\n",
    "        Province = row[0]\n",
    "        Canton = row[1]\n",
    "        District = row[2]\n",
    "        nonMatches.append((Province,Canton,District))\n",
    "    return nonMatches\n",
    "\n",
    "non_matches = find_non_matches(oij_df,new_df)\n",
    "\n",
    "print(non_matches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "428dffc9",
   "metadata": {},
   "source": [
    "En la siguiente celda se encarga de encontrar la cantidad de datos que no hacen match en el distrito entre el dataframe del inec y el dataframe del oij. Para esto se utilizo la funcion count de spark. El parametro de la funcion son dos dataframes y el retorno es un entero con la cantidad de datos que no hacen match entre los dos dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberOfNonMatches(df1,df2):\n",
    "    df1Temp = df1.select(\"Distrito\")\n",
    "    df2Temp = df2.select(\"Distrito\")\n",
    "    df1Temp = df1Temp.subtract(df2Temp)\n",
    "    return df1Temp.count()\n",
    "\n",
    "print(numberOfNonMatches(oij_df,new_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "239e2ce8",
   "metadata": {},
   "source": [
    "En la siguiente celda se encarga de la conexion a la base de datos y la creacion de las tablas necesarias para el almacenamiento de los datos ya limpios y procesados. Se crean dos tablas una para el inec y otra para el oij."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create sql table from dataframe\n",
    "url = \"jdbc:postgresql://localhost:5432/etl\"\n",
    "mode = \"overwrite\"\n",
    "properties = {\"user\": \"postgres\", \" password\": \"Legolas00\", \"driver\": \"org.postgresql.Driver\"}\n",
    "\n",
    "new_df.write.jdbc(url=url, table=\"INEC\", mode=mode, properties=properties)\n",
    "oij_df.write.jdbc(url=url, table=\"OIJ\", mode=mode, properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizcion para Compara la cantidad de delitos y la tasa de ocupación para los 10 distritos con más delitos en el país. \n",
    "df = pandas.read_sql_query('SELECT \"oij\".\"Distrito\", COUNT(\"oij\".\"Distrito\") AS \"Cantidad de delitos\", \"tasaOcupacion\" FROM \"oij\" INNER JOIN \"inec\" ON \"oij\".\"Distrito\" = \"inec\".\"Distrito\" and \"oij\".\"Canton\" = \"inec\".\"Canton\" and \"oij\".\"Provincia\" = \"inec\".\"Provincia\" GROUP BY \"oij\".\"Distrito\", \"tasaOcupacion\" ORDER BY COUNT(\"oij\".\"Distrito\") DESC LIMIT 10', con=engine)\n",
    "df.plot(x='Distrito', y=['Cantidad de delitos', 'tasaOcupacion'], kind='bar', figsize=(20,10), title='Cantidad de delitos y tasa de ocupación para los 10 distritos con más delitos en el país')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93135fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph for the days of the week with more crimes\n",
    "df = pandas.read_sql_query('SELECT \"oij\".\"Fecha\" from oij', con=engine)\n",
    "df['Fecha'] = pandas.to_datetime(df['Fecha'])\n",
    "df['Fecha'] = df['Fecha'].dt.day_name()\n",
    "df = df.groupby('Fecha').size().reset_index(name='Cantidad de delitos')\n",
    "df.plot.bar(x='Fecha', y='Cantidad de delitos', rot=0, figsize=(20,10))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c95571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph for count of type of delitos by distrito\n",
    "def generate_graph(distrito):\n",
    "    df = pandas.read_sql_query('SELECT \"oij\".\"Delito\" from oij where \"oij\".\"Distrito\" = \\'' + distrito + '\\' ', con=engine)\n",
    "    df = df.groupby('Delito').size().reset_index(name='Cantidad de delitos')\n",
    "    df.plot.bar(x='Delito', y='Cantidad de delitos', rot=0, figsize=(20,10))\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "generate_graph('hospital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph for count of delitos by genero\n",
    "df = pandas.read_sql_query('SELECT \"oij\".\"Genero\" from oij', con=engine)\n",
    "df = df.groupby('Genero').size().reset_index(name='Cantidad de delitos')\n",
    "df.plot.bar(x='Genero', y='Cantidad de delitos', rot=0, figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5fc0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph for count of delitos by provincia\n",
    "df = pandas.read_sql_query('SELECT \"oij\".\"Provincia\" from oij', con=engine)\n",
    "df = df.groupby('Provincia').size().reset_index(name='Cantidad de delitos')\n",
    "df.plot.bar(x='Provincia', y='Cantidad de delitos', rot=0, figsize=(30,20))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
